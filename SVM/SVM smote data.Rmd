---
title: "SVM - Assignment 2"
author: "Johan Sentosa"
date: '2022-05-09'
output:
  html_document:
    fig_caption: no
    number_sections: no
    self_contained: yes
    theme: flatly
    toc: true
    toc_depth: 2
    toc_float: true
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

# Import Libraries
```{r}
library(e1071)  # for svm
library(caret)
library(dplyr) 
```



# Load data
```{r}
diabetic.data <- read.csv('../data/train_SMOTE_oversampled.csv', header=TRUE)
head(diabetic.data)
#dim(diabetic.data)

```

```{r}

diabetic.data$readmitted <- factor(diabetic.data$readmitted)

```



```{r from https://rpubs.com/markloessi/506713}

start_time <- Sys.time()
folds = createFolds(diabetic.data$readmitted, k = 5)

svm.output = lapply(folds, function(x) { # start of function
  training_fold = diabetic.data[-x, ]
  test_fold = diabetic.data[x, ]

  classifier = svm(formula = readmitted ~ .,
                   data = training_fold,
                   type = 'C-classification',
                   kernel = 'radial')
  
  x_test <- subset(test_fold, select = -readmitted )
  y_pred <- predict(classifier, x_test)
  y_true <- factor(test_fold$readmitted)

  
  return(list(predicted=y_pred, actual=y_true))
})
print(Sys.time()-start_time)

```

```{r}
# Compute the performance metrics
cm<-lapply(svm.output, function(x) confusionMatrix(x$actual, x$predicted))

acc <- vapply(cm, function(c) c[["overall"]][["Accuracy"]], numeric(1))
metrics <- c("Precision", "Recall","F1")
metrics.by.class <- lapply(cm, function(c) c[["byClass"]][,metrics])

get.macro.average <- function(c) {
    re <- sum(c[, "Recall"]) / nrow(c)
    pr <- sum(c[, "Precision"]) / nrow(c)
    f1 <- sum(c[, "F1"]) / nrow(c)
    return(list(Avg.Precision=pr, Avg.Recall=re, Avg.F1.Score=f1))
}
avg.metrics <- sapply(metrics.by.class, get.macro.average)
all.metrics <- rbind(Accuracy=acc, avg.metrics)
all.metrics

```

```{r}
saveRDS(all.metrics, file = "output/metrics_smote_data.rds")
```


# Predict test data
```{r predict test data}
test_raw <- read.csv('../data/test_raw.csv', header=TRUE)
head(test_raw)
```


```{r}
dummy <- dummyVars(" ~ .", data=test_raw)
oh.df.test <- data.frame(predict(dummy, newdata = test_raw))

#getting label back
#class1
class1 <- subset(oh.df.test, oh.df.test$readmitted.30 == 1) #<30 
class1 <- class1 %>% select(-c('readmitted.30.1', 'readmittedNO', 'readmitted.30'))
class1$readmitted <- "<30"

#class2
class2 <- subset(oh.df.test, oh.df.test$readmittedNO == 1) #NO
class2 <- class2 %>% select(-c('readmitted.30.1', 'readmitted.30','readmittedNO'))
class2$readmitted <- "NO"

#class3
class3 <- subset(oh.df.test, oh.df.test$readmitted.30.1 == 1) #>30
class3 <- class3 %>% select(-c('readmitted.30.1', 'readmitted.30','readmittedNO'))
class3$readmitted <- ">30"

#Combine all
df_test <- rbind(class1, class2, class3)
df_test$readmitted <- factor(df_test$readmitted)
head(df_test)
```



```{r}
start_time = Sys.time()

classifier = svm(formula = readmitted ~ .,
                   data = diabetic.data,
                   type = 'C-classification',
                   kernel = 'radial')
print(Sys.time()-start_time)
#saveRDS(classifier, file = "output/model_smote_data.rds")

```

```{r}
# Predict test data
start_time = Sys.time()
pred_svm_test_train_smote_oversampled_sub <- predict(classifier, newdata = df_test)
pred_svm_test_train_smote_oversampled_sub <- factor(pred_svm_test_train_smote_oversampled_sub, order = TRUE, levels = c("NO", ">30", "<30"))
print(Sys.time()-start_time)

#Evaluate prediction 
cm_test_smote <- confusionMatrix(pred_svm_test_train_smote_oversampled_sub, df_test$readmitted)
cm_test_smote
```
```{r}
saveRDS(cm_test_smote, file = "output/cm_test_smote.rds")

```
